# src/checklist_api/api_connection.py
# Reads URL/username/password from a local "env" file.
# Produces a DataFrame with columns EXACTLY matching your legacy file:
# ['Number','Sub-Section','Compliance Name','Verifiable Requirement',
#  'Inclusion Criteria','Exclusion Criteria','citation','section_title']

from __future__ import annotations

import json
import time
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Tuple, Optional

import pandas as pd
import requests

# --------------------------- env loader --------------------------------------
_ENV_CACHE: Dict[str, str] | None = None

def load_env(path: str | Path = "env") -> Dict[str, str]:
    global _ENV_CACHE
    if _ENV_CACHE is not None:
        return _ENV_CACHE
    p = Path(path)
    if not p.exists():
        raise FileNotFoundError(
            "Secrets file 'env' not found. Create it with:\n"
            "CHECKLIST_API_BASE_URL=...\nACQUIRE_USER=...\nACQUIRE_PASS=..."
        )
    data: Dict[str, str] = {}
    for raw in p.read_text(encoding="utf-8").splitlines():
        line = raw.strip()
        if not line or line.startswith("#") or "=" not in line:
            continue
        k, v = line.split("=", 1)
        data[k.strip()] = v.strip().strip('"').strip("'")
    _ENV_CACHE = data
    return data

def get_env(key: str, default: str = "") -> str:
    return load_env().get(key, default)

# --------------------------- config -----------------------------------------
API_BASE: str = get_env("CHECKLIST_API_BASE_URL").rstrip("/")
API_USER: str = get_env("ACQUIRE_USER")
API_PASS: str = get_env("ACQUIRE_PASS")

OUT_DIR = Path("results")           # Accure persists this workspace folder
SNAP_DIR = OUT_DIR / "snapshots"
OUT_DIR.mkdir(parents=True, exist_ok=True)
SNAP_DIR.mkdir(parents=True, exist_ok=True)

# --------------------------- utils ------------------------------------------
def utcnow_iso() -> str:
    return datetime.now(timezone.utc).isoformat()

def make_stem(title: int, section: str) -> str:
    sect = str(section).replace(".", "_").replace(" ", "")
    return f"T{int(title)}_S{sect}"

def safe_call(fn, *args, retries: int = 3, delay: float = 3.0, **kwargs):
    last_err = None
    for attempt in range(1, retries + 1):
        try:
            return fn(*args, **kwargs)
        except requests.RequestException as e:
            last_err = e
            if attempt < retries:
                time.sleep(delay)
            else:
                raise
    raise last_err

# --------------------------- auth & api --------------------------------------
def _login(username: str, password: str) -> str:
    if not API_BASE:
        raise RuntimeError("CHECKLIST_API_BASE_URL is not set in 'env'.")
    url = f"{API_BASE}/auth/login"
    resp = requests.post(url, json={"username": username, "password": password}, timeout=30)
    resp.raise_for_status()
    token = (resp.json().get("access_token") or resp.json().get("token") or "").strip()
    if not token:
        raise RuntimeError("Login succeeded but no token found in response.")
    return token

def _auth_header() -> Dict[str, str]:
    if not (API_BASE and API_USER and API_PASS):
        raise RuntimeError("Missing CHECKLIST_API_BASE_URL/ACQUIRE_USER/ACQUIRE_PASS in 'env'.")
    token = safe_call(_login, API_USER, API_PASS, retries=2, delay=2)
    return {"Authorization": f"Bearer {token}"}

def get_section(title_number: int, section_identifier: str) -> Dict[str, Any]:
    """Retrieve CFR section metadata/text (used to fill 'section_title')."""
    headers = _auth_header()
    sid = str(section_identifier).strip()
    url = f"{API_BASE}/titles/{int(title_number)}/sections/{sid}"
    resp = requests.get(url, headers=headers, timeout=30)
    resp.raise_for_status()
    return resp.json()

def get_checklist(title_number: int, section_identifier: str) -> Dict[str, Any]:
    """Retrieve the checklist/controls for a CFR section."""
    headers = _auth_header()
    sid = str(section_identifier).strip()
    url = f"{API_BASE}/checklist"
    params = {"title": int(title_number), "section": sid}
    resp = requests.get(url, params=params, headers=headers, timeout=60)
    resp.raise_for_status()
    return resp.json()

# --------------------------- normalization (exact schema) --------------------
LEGACY_COLS = [
    "Number",
    "Sub-Section",
    "Compliance Name",
    "Verifiable Requirement",
    "Inclusion Criteria",
    "Exclusion Criteria",
    "citation",
    "section_title",
]

def controls_to_exact_table(
    payload: Dict[str, Any],
    title_number: int,
    section_identifier: str,
    section_snapshot: Optional[Dict[str, Any]] = None
) -> pd.DataFrame:
    """
    Convert the API payload into the EXACT table schema used in your sample.
    """
    citation = f"{int(title_number)} CFR {section_identifier}"
    # Try common keys for the human-readable section title
    section_title = ""
    if isinstance(section_snapshot, dict):
        for k in ("section_title", "title", "heading", "name"):
            if k in section_snapshot and section_snapshot[k]:
                section_title = str(section_snapshot[k])
                break

    rows: List[Dict[str, Any]] = []
    controls = payload.get("controls") if isinstance(payload, dict) else None

    if isinstance(controls, list) and controls:
        for i, c in enumerate(controls, start=1):
            comp_name = c.get("name") or c.get("short") or ""
            text = c.get("text") or ""
            if not comp_name:
                # Fallback: take first sentence chunk as a "name"
                comp_name = (text.split(".")[0] if isinstance(text, str) and text else "")
            rows.append({
                "Number": i,
                "Sub-Section": c.get("subsection", ""),
                "Compliance Name": comp_name,
                "Verifiable Requirement": text,
                "Inclusion Criteria": c.get("inclusion", ""),
                "Exclusion Criteria": c.get("exclusion", ""),
                "citation": citation,
                "section_title": section_title,
            })
    else:
        # Fallback: markdown-to-rows if the API returns a markdown block
        md: str = str(payload.get("markdown", ""))
        for i, line in enumerate(md.splitlines(), start=1):
            line = line.strip("-*• ").strip()
            if not line:
                continue
            rows.append({
                "Number": i,
                "Sub-Section": "",
                "Compliance Name": line[:60],
                "Verifiable Requirement": line,
                "Inclusion Criteria": "",
                "Exclusion Criteria": "",
                "citation": citation,
                "section_title": section_title,
            })

    return pd.DataFrame(rows, columns=LEGACY_COLS)

# --------------------------- Accure-facing helpers ---------------------------
def test_connection() -> bool:
    """Quick preflight: confirms base URL and that login works."""
    try:
        _ = _auth_header()
        return bool(API_BASE)
    except Exception:
        return False

def fetch_checklist_pack(
    title_number: int,
    section_identifier: str,
    *,
    out_dir: Optional[str | Path] = None,
    return_frames: bool = True,
    file_ext: str = "csv"  # you can set "xls" to match your sample name if you want
) -> Tuple[pd.DataFrame, Dict[str, Any], Dict[str, Any]]:
    """
    1) Get section metadata (fills 'section_title')
    2) Get checklist JSON
    3) Convert to EXACT legacy table (columns/order)
    4) Save CSV (or .xls name with CSV content) under ./results (or out_dir)
    5) Return (df_exact, section_snapshot, status)
    """
    out_base = Path(out_dir) if out_dir else OUT_DIR
    snap_dir = out_base / "snapshots"
    out_base.mkdir(parents=True, exist_ok=True)
    snap_dir.mkdir(parents=True, exist_ok=True)

    section_snapshot = safe_call(get_section, title_number, section_identifier)
    checklist_payload = safe_call(get_checklist, title_number, section_identifier)

    # Table in EXACT schema you provided
    df_exact = controls_to_exact_table(checklist_payload, title_number, section_identifier, section_snapshot)

    stem = make_stem(title_number, section_identifier)
    # Note: content is CSV; extension can be '.csv' or '.xls' as a name preference
    out_name = f"checklist_{stem}.{file_ext}"
    out_csv = out_base / out_name
    out_json = snap_dir / f"snapshot_{stem}.json"

    df_exact.to_csv(out_csv, index=False)

    status = {
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "title": int(title_number),
        "section": str(section_identifier),
        "records_retrieved": int(len(df_exact)),
        "csv_path": str(out_csv),
        "snapshot_path": str(out_json),
        "api_base": API_BASE,
    }
    with open(out_json, "w", encoding="utf-8") as f:
        json.dump({"section": section_snapshot, "checklist": checklist_payload, "status": status}, f, indent=2)

    return (df_exact if return_frames else pd.DataFrame(columns=LEGACY_COLS)), section_snapshot, status

# Optional local smoke test
if __name__ == "__main__":
    TITLE = 10
    SECTION = "52.55"
    if not test_connection():
        raise SystemExit("❌ Preflight failed. Check CHECKLIST_API_BASE_URL/ACQUIRE_USER/ACQUIRE_PASS in 'env'.")
    df, section_info, status = fetch_checklist_pack(TITLE, SECTION, file_ext="xls")
    print(df.head(2).to_string(index=False))
    print(json.dumps(status, indent=2))
